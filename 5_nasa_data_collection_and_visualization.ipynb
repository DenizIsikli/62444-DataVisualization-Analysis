{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2：NASA Data Acquisation, Visualization, and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code makes sure that once there is change in the 'src/' folder, the \n",
    "# change will be automatically reloaded in the notebook.\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%aimport src"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Understanding the NASA API and Data Collection\n",
    "\n",
    "- Register for a NASA API key and understand the different types of data that the API provides.\n",
    "- Run the Python script below to fetch data about **Near Earth Objects (NEOs)** from the NASA API for a years data.\n",
    "- Extract and understand the different pieces of data provided for each NEO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from getpass import getpass\n",
    "\n",
    "# Set your NASA API KEY, this step asks you to enter your API KEY.\n",
    "# (The input box may be float in the top on your editor.)\n",
    "api_key = getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the start and end dates for the data you want to fetch\n",
    "start_date = datetime.strptime('2022-01-01', '%Y-%m-%d')\n",
    "end_date = start_date + timedelta(days=365)  # 1 year later\n",
    "\n",
    "# Initialize a list to store the data\n",
    "data = []\n",
    "\n",
    "# Fetch data from the NASA API 7 days at a time\n",
    "# The introduction of the API is on https://api.nasa.gov, under \"Browse APIs\" -> \"Asteroids NeoWs\"\n",
    "# You can look into the example query in the link below to see what the data look like:\n",
    "# https://api.nasa.gov/neo/rest/v1/feed?start_date=2015-09-07&end_date=2015-09-08&api_key=DEMO_KEY\n",
    "current_date = start_date\n",
    "while current_date < end_date:\n",
    "    next_date = min(current_date + timedelta(days=7), end_date)\n",
    "    response = requests.get(f'https://api.nasa.gov/neo/rest/v1/feed?start_date={current_date.strftime(\"%Y-%m-%d\")}&end_date={next_date.strftime(\"%Y-%m-%d\")}&api_key={api_key}')\n",
    "    data.append(response.json())\n",
    "    current_date = next_date + timedelta(days=1) #Incremented current_date by a day. Necessary to prevent overlap\n",
    "    time.sleep(1)  # To avoid hitting the rate limit\n",
    "\n",
    "# Now 'data' contains the NEO data for the 1-year period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2022-01-01', '2022-01-02', '2022-01-03', '2022-01-04', '2022-01-05', '2022-01-06', '2022-01-07', '2022-01-08', '2022-01-09', '2022-01-10', '2022-01-11', '2022-01-12', '2022-01-13', '2022-01-14', '2022-01-15']\n"
     ]
    }
   ],
   "source": [
    "# Check the date coverage of your data.\n",
    "dates_contained_in_data = []\n",
    "for d in data:\n",
    "    dates_contained_in_data += list(d['near_earth_objects'].keys())\n",
    "\n",
    "print(sorted(dates_contained_in_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import get_a_random_chunk_property\n",
    "get_a_random_chunk_property(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the remaining tasks, you have to organize the data as pd.DataFrame so as to suit the specific need in each task. This part may require a considerably amount of efforts, which is normal in data science and analytics works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [],
   "source": [
    "#Save to pickle\n",
    "import pickle\n",
    "with open('NASAdata_raw.pkl', 'wb') as f:\n",
    "    pickle.dump(data, f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [],
   "source": [
    "#Import from pickle\n",
    "import pickle\n",
    "with open('NASAdata_raw.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "data": {
      "text/plain": "           id                 name  absolute_magnitude_h        date\n0     2216523    216523 (2001 HY7)                 20.70  2022-01-07\n1     2494697   494697 (2004 SW55)                 20.77  2022-01-07\n2     2496860  496860 (1999 XL136)                 19.67  2022-01-07\n3     3311963           (2006 AL4)                 24.92  2022-01-07\n4     3401388            (2008 CO)                 22.60  2022-01-07\n..        ...                  ...                   ...         ...\n254  54236582           (2022 AU5)                 26.20  2022-01-13\n255  54236938           (2022 AS6)                 24.84  2022-01-13\n256  54236939           (2022 AT6)                 23.23  2022-01-13\n257  54240415           (2022 BH4)                 22.12  2022-01-13\n258  54357255           (2023 HG7)                 27.04  2022-01-13\n\n[259 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>name</th>\n      <th>absolute_magnitude_h</th>\n      <th>date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2216523</td>\n      <td>216523 (2001 HY7)</td>\n      <td>20.70</td>\n      <td>2022-01-07</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2494697</td>\n      <td>494697 (2004 SW55)</td>\n      <td>20.77</td>\n      <td>2022-01-07</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2496860</td>\n      <td>496860 (1999 XL136)</td>\n      <td>19.67</td>\n      <td>2022-01-07</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3311963</td>\n      <td>(2006 AL4)</td>\n      <td>24.92</td>\n      <td>2022-01-07</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3401388</td>\n      <td>(2008 CO)</td>\n      <td>22.60</td>\n      <td>2022-01-07</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>254</th>\n      <td>54236582</td>\n      <td>(2022 AU5)</td>\n      <td>26.20</td>\n      <td>2022-01-13</td>\n    </tr>\n    <tr>\n      <th>255</th>\n      <td>54236938</td>\n      <td>(2022 AS6)</td>\n      <td>24.84</td>\n      <td>2022-01-13</td>\n    </tr>\n    <tr>\n      <th>256</th>\n      <td>54236939</td>\n      <td>(2022 AT6)</td>\n      <td>23.23</td>\n      <td>2022-01-13</td>\n    </tr>\n    <tr>\n      <th>257</th>\n      <td>54240415</td>\n      <td>(2022 BH4)</td>\n      <td>22.12</td>\n      <td>2022-01-13</td>\n    </tr>\n    <tr>\n      <th>258</th>\n      <td>54357255</td>\n      <td>(2023 HG7)</td>\n      <td>27.04</td>\n      <td>2022-01-13</td>\n    </tr>\n  </tbody>\n</table>\n<p>259 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "temp_dfs = []   #Create a temp list to store all the dataframe we are going to generate\n",
    "\n",
    "for d in data:      #The way the data is saved to a list leaves it in pieces that we have to go over\n",
    "    for day in d['near_earth_objects']:\n",
    "        subset = d['near_earth_objects'][day]   #We take a subset consisting of all object logged that day\n",
    "        df_temp = pd.json_normalize(subset)     #Turn the subset into a dataframe\n",
    "        df_temp = df_temp[['id', 'name', 'absolute_magnitude_h']]   #Retrieve the columns we want\n",
    "        df_temp['date'] = day       #Save the date in a new column\n",
    "        temp_dfs.append(df_temp)    #Save the dataframe in a temp list\n",
    "\n",
    "df = pd.concat(temp_dfs, ignore_index=True)     #Combine all the saved dataframes\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [],
   "source": [
    "#Save to pickle\n",
    "import pickle\n",
    "with open('NASAdata_df.pkl', 'wb') as f:\n",
    "    pickle.dump(df, f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [],
   "source": [
    "#Import from pickle\n",
    "import pickle\n",
    "with open('NASAdata_df.pkl', 'rb') as f:\n",
    "    df = pickle.load(f)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Data Analysis\n",
    "\n",
    "- Calculate the average size of the NEOs for each day.\n",
    "- Determine the proportion of NEOs that are potentially hazardous.\n",
    "- Find the NEO with the closest approach distance for each day.\n",
    "- Use statistical methods to analyze the data. For example, calculate the mean, median, mode, and standard deviation of the NEO sizes. Determine if the size of a NEO is correlated with whether it is potentially hazardous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Data Visualization Part A\n",
    "\n",
    "- Create a line plot of the number of NEOs per week.\n",
    "- Create a histogram of the distribution of NEO sizes.\n",
    "- Create a bar plot of the average NEO size per week.\n",
    "- Use a library like Seaborn to create more complex visualizations, such as a box plot of the NEO sizes or a heat map of the number of NEOs per week. **Be creative**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Data Visualization Part B\n",
    "\n",
    "- Create a pie chart of the proportion of hazardous vs non-hazardous NEOs.\n",
    "- Create a scatter plot of the correlation between NEO size and close approach distance.\n",
    "- Customize the appearance of your plots (e.g., colors, labels, titles).\n",
    "- Create interactive visualizations using a library like Plotly. For example, create an interactive scatter plot where you can hover over each point to see more information about the NEO. **Be creative!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5: Interpretation of Results\n",
    "\n",
    "- Interpret the results of your data visualization in part A and B. \n",
    "- What insights can you gain about NEOs from your results? Summarizing your findings.\n",
    "- Use your findings to make predictions or recommendations. For example, if you found that larger NEOs are more likely to be potentially hazardous, you could recommend that more resources be allocated to tracking large NEOs. **Be creative!**\n",
    "- Identify, understand, and explain one scientific paper, on a clustering or classification method of relevance that could help Task 5. You don't have to implement it, you just need to justify in this notebook why the method in the scientific paper could contribute in analysis or interpretation of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6: Presentation and Documentation\n",
    "\n",
    "- Make this project as part of your presentation, **using beamer in LaTeX**. \n",
    "- This should include an overview of your work, the results of your data analysis, and the insights you gained from your results."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
